{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0aa6c5189c07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_anaconda\\envs\\keras\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# We still need all the names that are toplevel on tensorflow_core\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# These should not be visible in the main tf module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Author: Sang Yuchen\n",
    "Date:2020/05/31\n",
    "Desc: mlp for text classification adversarial examples discriminating\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "#超参数设置\n",
    "vocab_size=10000\n",
    "seq_length=80\n",
    "buffer_length=1000\n",
    "embedding_dim=100\n",
    "node_num=(embedding_dim * seq_length + 1) *2/3     #MLP隐藏层节点数\n",
    "\n",
    "batch_size=32\n",
    "epochs=10\n",
    "learning_rate=0.001\n",
    "n_samples = 4000\n",
    "total_samples=12500\n",
    "\n",
    "#数据处理\n",
    "imdb=keras.datasets.imdb\n",
    "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "word_index=imdb.get_word_index()\n",
    "word_index={k:(v+3) for k,v in word_index.items()}\n",
    "\n",
    "word_index['<PAD>']=0\n",
    "word_index['<START>']=1\n",
    "word_index['<UNK>']=2\n",
    "word_index['<EOS>']=3\n",
    "\n",
    "index_word=dict([(value,key)for(key,value)in word_index.items()])\n",
    "\n",
    "def decode_review(review):\n",
    "    \"\"\"\n",
    "\n",
    "    :param review: 一条评论，是一个整数序列\n",
    "    :return: 一条评论，是一个英文单词序列\n",
    "    \"\"\"\n",
    "    return ' '.join([index_word.get(word,'<UNK>')for word in review])\n",
    "\n",
    "#data_with_START_token :\n",
    "# shape: sample_num,seq_length+1\n",
    "# Desc: decoder input data\n",
    "train_data_with_START_token = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "           value=word_index['<PAD>'], padding='post', truncating='post', maxlen=seq_length+1)\n",
    "test_data_with_START_token = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "           value=word_index['<PAD>'], padding='post', truncating='post', maxlen=seq_length + 1)\n",
    "\n",
    "\n",
    "db_train=tf.data.Dataset.from_tensor_slices((train_data_with_START_token,train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_label_0 = tf.data.Dataset.from_tensor_slices([data[1:] for data, label in db_train.as_numpy_iterator()\n",
    "                                           if label == 0])\n",
    "ds_label_1 = tf.data.Dataset.from_tensor_slices([data[1:]  for data, label in db_train.as_numpy_iterator()\n",
    "                                           if label == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_label_0 = ds_label_0.shuffle(buffer_size=buffer_length).batch(batch_size=batch_size,drop_remainder=False)\n",
    "ds_label_1 = ds_label_1.shuffle(buffer_size=buffer_length).batch(batch_size=batch_size,drop_remainder=False)\n",
    "next(iter(ds_label_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
